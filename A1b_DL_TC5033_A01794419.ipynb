{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igquinteroch/deep-learning-coursework/blob/main/A1b_DL_TC5033_A01794419.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qBh7DOP-2tC"
      },
      "source": [
        "# TC 5033\n",
        "## Deep Learning\n",
        "## Fully Connected Deep Neural Networks\n",
        "\n",
        "### Activity 1b: Implementing a Fully Connected Network for Kaggle ASL Dataset\n",
        "\n",
        "## Objective\n",
        "\n",
        "The aim of this part of the activity is to apply your understanding of Fully Connected Networks by implementing a multilayer network for the [Kaggle ASL (American Sign Language) dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet).\n",
        "\n",
        "While you have been provided with a complete solution for a Fully Connected Network using Numpy for the MNIST dataset, you are encouraged to try to come up with the solution.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "  This activity requires submission in teams of 3 or 4 members. Submissions from smaller or larger teams will not be accepted unless prior approval has been granted (only due to exceptional circumstances).\n",
        "  \n",
        "  While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell).\n",
        "  \n",
        "  Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
        "\n",
        "  * Load and Preprocess Data: You are provided a starter code to load the data. Be sure to understand the code.\n",
        "\n",
        "  * Review MNIST Notebook (Optional): Before diving into this activity, you have the option to revisit the MNIST example to refresh your understanding of how to build a Fully Connected Network using Numpy.\n",
        "\n",
        "  * Start Fresh: Although you can refer to the MNIST solution at any point, try to implement the network for the ASL dataset on your own. This will reinforce your learning and understanding of the architecture and mathematics involved.\n",
        "\n",
        "  * Implement Forward and Backward Pass: Write the code to perform the forward and backward passes, keeping in mind the specific challenges and characteristics of the ASL dataset.\n",
        "    \n",
        "  * Design the Network: Create the architecture of the Fully Connected Network tailored for the ASL dataset. Choose the number of hidden layers, neurons, and hyperparameters judiciously.\n",
        "\n",
        "  * Train the Model: Execute the training loop, ensuring to track performance metrics such as loss and accuracy.\n",
        "\n",
        "  * Analyze and Document: Use Markdown cells to document in detail the choices you made in terms of architecture and hyperparameters, you may use figures, equations, etc to aid in your explanations. Include any metrics that help justify these choices and discuss the model's performance.  \n",
        "\n",
        "## Evaluation Criteria\n",
        "\n",
        "* Code Readability and Comments\n",
        "* Appropriateness of chosen architecture and hyperparameters for the ASL dataset\n",
        "* Performance of the model on the ASL dataset (at least 70% acc)\n",
        "* Quality of Markdown documentation\n",
        "\n",
        "## Submission\n",
        "\n",
        "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the libraries and set the stage\n",
        "\n",
        "\n",
        "* `numpy`: Performs mathematical operations on large arrays or matrices.\n",
        "* `string`: Provides utilities for string processing.\n",
        "* `pandas`: Used for data manipulation.\n",
        "* `matplotlib.pyplot`: Used for plotting data.\n",
        "* `cv2`: Used for image processing.\n",
        "* `os`: Allows interaction with the OS - e.g., directory navigation."
      ],
      "metadata": {
        "id": "V5ZyLLufuovh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qt6iXs5T-2tE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8505c3e4-1883-4275-afbd-e78e25c928ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import os\n",
        "\n",
        "# Enabling autoreload in the Jupyter Notebook\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Show plots inline in the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Provides access to the Drive from within the notebook\n",
        "from google.colab import drive\n",
        "\n",
        "# Mounts the Drive into the Colab environment\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Changes the current working directory to the specified path in Google Drive.\n",
        "os.chdir(\"/content/drive/MyDrive/TC5033.10\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2T9bfL4U-2tE"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/TC5033.10/asl_data\"\n",
        "\n",
        "# Loading the training dataset\n",
        "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv')) # os.path.join() basically combines the DATA_PATH with the filename to create a full path to the file\n",
        "\n",
        "# Loading the validation dataset\n",
        "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "UPSKDme7-2tE",
        "outputId": "6cf51fa7-6028-413c-fbfb-9c56c4638721"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      3     107     118     127     134     139     143     146     150   \n",
              "1      6     155     157     156     156     156     157     156     158   \n",
              "2      2     187     188     188     187     187     186     187     188   \n",
              "3      2     211     211     212     212     211     210     211     210   \n",
              "4     12     164     167     170     172     176     179     180     184   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0     153  ...       207       207       207       207       206       206   \n",
              "1     158  ...        69       149       128        87        94       163   \n",
              "2     187  ...       202       201       200       199       198       199   \n",
              "3     210  ...       235       234       233       231       230       226   \n",
              "4     185  ...        92       105       105       108       133       163   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0       206       204       203       202  \n",
              "1       175       103       135       149  \n",
              "2       198       195       194       195  \n",
              "3       225       222       229       163  \n",
              "4       157       163       164       179  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5fa52aa6-2c8a-4cc3-b84a-006d7bd6d28b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>...</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fa52aa6-2c8a-4cc3-b84a-006d7bd6d28b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5fa52aa6-2c8a-4cc3-b84a-006d7bd6d28b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5fa52aa6-2c8a-4cc3-b84a-006d7bd6d28b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-76db4391-3ff8-45d6-9960-456d7c12669f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76db4391-3ff8-45d6-9960-456d7c12669f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-76db4391-3ff8-45d6-9960-456d7c12669f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Checking the first samples\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo0d5FlJ-2tF"
      },
      "source": [
        "### Import Images and Data Processing\n",
        "\n",
        "The following section prepares the data for training and validation by separating the target labels (the ASL signs) from the input features (the data used to predict the signs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gAQwhN4z-2tF"
      },
      "outputs": [],
      "source": [
        "# Convert the 'label' column in the training and validation sets to a NumPy array\n",
        "y_train = np.array(train_df['label'])\n",
        "y_val = np.array(valid_df['label'])\n",
        "\n",
        "# Remove the 'label' column from the original training and validation sets\n",
        "# Keep only the input features\n",
        "del train_df['label']\n",
        "del valid_df['label']\n",
        "\n",
        "# Convert the remaining features data in the training and validation sets to NumPy arrays of type float32\n",
        "# float32 - common practice in deep learning for numerical stability and performance\n",
        "x_train = train_df.values.astype(np.float32)\n",
        "x_val = valid_df.values.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "code_folding": [],
        "id": "Hjo3IGIZ-2tF"
      },
      "outputs": [],
      "source": [
        "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
        "    '''\n",
        "    This function splits any dataset into two subsets (validation set and test set)\n",
        "    It helps to assess how well the model generalizes to new data\n",
        "\n",
        "    Parameters:\n",
        "        x (np.ndarray): The feature data (input values)\n",
        "        y (np.ndarray): The labels corresponding to the feature data.\n",
        "        pct (float): The proportion of the data to allocate to the test set. Default is 0.5 (50%)\n",
        "        shuffle (bool): Whether to shuffle the data before splitting. Default is True.\n",
        "    '''\n",
        "    # Create shuffled indices for randomizing the dataset\n",
        "    if shuffle:\n",
        "        # Creates a sequence of numbers representing the indices of each data point\n",
        "        indices = np.arange(len(x))\n",
        "        np.random.shuffle(indices)\n",
        "        # Reorder the dataset based on the shuffled indices\n",
        "        x = x[indices]\n",
        "        y = y[indices]\n",
        "\n",
        "    # Calculate the split index based on the percentage allocated to the test set\n",
        "    split_idx = int(len(x) * (1 - pct))\n",
        "\n",
        "    # Split the data into validation and test sets\n",
        "    x_val, x_test = x[:split_idx], x[split_idx:]\n",
        "    y_val, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "    return x_val, y_val, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WLu6Kxxo-2tF"
      },
      "outputs": [],
      "source": [
        "# Split the validation set into a smaller validation set and a test set\n",
        "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "y-AiHVAD-2tF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4a6d7c-6e45-4b11-c224-495368cc6de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ],
      "source": [
        "# Creates a list of all lowercase letters in the alphabet\n",
        "# They involve motion and can't be represented in a static image format\n",
        "alphabet=list(string.ascii_lowercase)\n",
        "alphabet.remove('j')\n",
        "alphabet.remove('z')\n",
        "print(len(alphabet))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJsf9MJl-2tF"
      },
      "source": [
        "### Normalise\n",
        "\n",
        "The following section normalizes the dataset to improve the performance and stability of the model.\n",
        "\n",
        "1. Subtrack the mean and divide it by the standard deviation.\n",
        "2. Compute the mean and standard deviation of the training data.\n",
        "3. Normalize the datasets using the training statistics.\n",
        "\n",
        "**Normalization**\n",
        "\n",
        "It ensures the feature values have a consistent scale, typically with a mean of 0 and a std of 1.\n",
        "\n",
        "**Data leakage**\n",
        "\n",
        "Occurs when a model uses information during training that wouldn't be available at the time of prediction. It leads to overfitting."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalise(x_mean, x_std, x_data):\n",
        "    return (x_data - x_mean) / x_std"
      ],
      "metadata": {
        "id": "X9VWppWJib-h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean is calculated only on the training data to avoid data leakage\n",
        "x_mean = x_train.mean()\n",
        "# Standard deviation is calculated only on the training data\n",
        "x_std = x_train.std()\n",
        "\n",
        "# Normalize the datasets using the training statistics\n",
        "x_train = normalise(x_mean, x_std, x_train)\n",
        "x_val = normalise(x_mean, x_std, x_val)\n",
        "x_test = normalise(x_mean, x_std, x_test)"
      ],
      "metadata": {
        "id": "qQXqvAnMiiIr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After normalization, the mean should be close to 0 and std close to 1\n",
        "x_train.mean(), x_train.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4hnmf1vijnl",
        "outputId": "f1cc3967-8861-47ce-d031-dec4fa1f393a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.6268384e-06, 0.99999946)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKZ0AIoH-2tG"
      },
      "source": [
        "### Plot samples\n",
        "\n",
        "The following section helps to visualize and inspect random samples from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_number(image):\n",
        "    # Create a figure with 5x5 inch size\n",
        "    plt.figure(figsize=(5,5))\n",
        "    # Show the image in grayscale\n",
        "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
        "    # Remove the axes\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NB_rlDN_iUT8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a random index from the test set\n",
        "rnd_idx = np.random.randint(len(y_test)) # Generate a random integer between 0 and the length of y_test\n",
        "\n",
        "# Assign the labels from the dataset\n",
        "label_to_sign = {0: 'A',\n",
        "                 1: 'B',\n",
        "                 2: 'C',\n",
        "                 3: 'D',\n",
        "                 4: 'E',\n",
        "                 5: 'F',\n",
        "                 6: 'G',\n",
        "                 7: 'H',\n",
        "                 8: 'I',\n",
        "                 9: 'K',\n",
        "                 10: 'L',\n",
        "                 11: 'M',\n",
        "                 12: 'N',\n",
        "                 13: 'O',\n",
        "                 14: 'P',\n",
        "                 15: 'Q',\n",
        "                 16: 'R',\n",
        "                 17: 'S',\n",
        "                 18: 'T',\n",
        "                 19: 'U',\n",
        "                 20: 'V',\n",
        "                 21: 'W',\n",
        "                 22: 'X',\n",
        "                 23: 'Y',\n",
        "                 24: 'Y'}  # Excluding 'J' and 'Z'\n",
        "print(f'The image represents the sign: {label_to_sign[y_test[rnd_idx]]}')\n",
        "print(f'The value represents the sign: {y_test[rnd_idx]}')\n",
        "\n",
        "# Reshape and plot the selected test image\n",
        "plot_number(x_test[rnd_idx].reshape(28,28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "k2VZuB1LiWIX",
        "outputId": "621eda21-1eef-4834-b7dc-e0cd7c1c95a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image represents the sign: K\n",
            "The value represents the sign: 9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wACP0vmV-2tG"
      },
      "source": [
        "### Equations provided for our model\n",
        "\n",
        "$$z^1 = W^1 X + b^1$$\n",
        "\n",
        "$$a^1 = ReLU(z^1) $$\n",
        "\n",
        "\n",
        "$$z^2 = W^2 a^1 + b^2$$\n",
        "\n",
        "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
        "\n",
        "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
        "\n",
        "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB-9nDMC-2tG"
      },
      "source": [
        "#### Create mini batches\n",
        "\n",
        "The following section divides the section into smaller subsets called **mini-batches.**\n",
        "\n",
        "They make the training process faster and more effective at learning from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OzT_mq4x-2tG"
      },
      "outputs": [],
      "source": [
        "def create_minibatches(mb_size, x, y, shuffle=True):\n",
        "    '''\n",
        "    Creates minibatches from the dataset.\n",
        "\n",
        "    Parameters:\n",
        "        mb_size (int): The size of each minibatch.\n",
        "        x (np.ndarray): Input data of shape (num_samples, num_features).\n",
        "        y (np.ndarray): Labels of shape (num_samples) from the input data.\n",
        "        shuffle (bool): Whether to shuffle the data before creating minibatches. Default is True.\n",
        "    '''\n",
        "    assert x.shape[0] == y.shape[0], 'Mismatch minibatch size'\n",
        "\n",
        "    # Total number of samples in the dataset\n",
        "    total_data = x.shape[0]\n",
        "\n",
        "    if shuffle:\n",
        "      # Create an array of indices [0, 1, 2, ..., total_data-1]\n",
        "      idxs = np.arange(total_data)\n",
        "      # Randomly shuffle the indices to randomize the order of the data\n",
        "      np.random.shuffle(idxs)\n",
        "      # Reorder `x` based on the shuffled indices\n",
        "      x = x[idxs]\n",
        "      # Reorder `y` based on the shuffled indices\n",
        "      y = y[idxs]\n",
        "\n",
        "    # Generate minibatches by iterating through the data in steps of `mb_size`\n",
        "    for i in range(0, total_data, mb_size):\n",
        "      yield x[i:i + mb_size], y[i:i + mb_size]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w43uoHan-2tG"
      },
      "source": [
        "## Linear, ReLU, and Sequential Classes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate attributes to the parameters using the below class\n",
        "\"\"\"\n",
        "(np.ndarray): This indicates that the new class ´np_tensor´ inherits from the ´np.ndarray´ class.\n",
        "´np.ndarray´ is the core class in the NumPy library representing multi-dimensional arrays.\n",
        "By inheriting from ´np.darray´, ´np_tensor´ gets all the functionality of NumPy arrays.\n",
        "\"\"\"\n",
        "\n",
        "class np_tensor(np.ndarray): pass"
      ],
      "metadata": {
        "id": "Mj_Mc0tuc774"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrJOyHnj-2tG"
      },
      "source": [
        "###  Linear Class\n",
        "\n",
        "$$z^1 = W^1 X + b^1$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear():\n",
        "    def __init__(self, input_size, output_size):\n",
        "        '''\n",
        "        Init parameters using Kaiming He initialization\n",
        "\n",
        "        Parameters:\n",
        "          self: instance of the class.\n",
        "          input_size: number of input features (from previous layer)\n",
        "          output_size: number of output features (to the next layer)\n",
        "        Atributes:\n",
        "          self.W (np.ndarray): Weight matrix of shape (output_size, input_size)\n",
        "          self.b (np.ndarray): Bias vector of shape (output_size, 1)\n",
        "        '''\n",
        "\n",
        "      # Initialize the weights using Kaiming He initialization\n",
        "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor) # Scale weights by 1/sqrt(input_size / 2) for better gradient flow in deep networks\n",
        "      # Initialize the biases to zero\n",
        "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
        "\n",
        "\n",
        "    def __call__(self, X): # lineal class forward\n",
        "        '''\n",
        "        Performs the forward pass of the linear layer.\n",
        "\n",
        "        Parameters:\n",
        "          X (np.ndarray): Input data of shape, (input_size, batch_size), where batch_size is the number of samples.\n",
        "        Returns:\n",
        "          Z (np.ndarray): Output of the linear transformation (output size, batch_size) - computed as Z= W @ X + b).\n",
        "\n",
        "        '''\n",
        "        # Forward pass\n",
        "        Z = self.W @ X + self.b\n",
        "        return Z\n",
        "\n",
        "\n",
        "    def backward(self, X, Z):\n",
        "        '''\n",
        "        Performs the backward pass of the linear layer.\n",
        "\n",
        "        Parameters:\n",
        "          X (np.ndarray): Input data from the forward pass, (input_size, batch_size).\n",
        "          Z (np.ndarray): Output from the forward pass (contains the gradients as `Z.grad`).\n",
        "        '''\n",
        "        # Compute the gradient of the input (backpropagate through the weights)\n",
        "        X.grad = self.W.T @ Z.grad\n",
        "\n",
        "        # Compute the gradient of the weights\n",
        "        self.W.grad = Z.grad @ X.T\n",
        "\n",
        "        # Compute the gradient of the biases (sum the gradients over all samples)\n",
        "        self.b.grad = np.sum(Z.grad, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "SvO2xqj-eNmp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzF9IdHE-2tG"
      },
      "source": [
        "### ReLU Class\n",
        "\n",
        "In the following section, we apply the ReLU activation function to the input data (input data coming from the activation function of the previous layer).\n",
        "\n",
        "$$a^1 = ReLU(z^1) $$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU():\n",
        "    def __call__(self, Z):\n",
        "        '''\n",
        "        Forward pass of the ReLU activation function\n",
        "\n",
        "        Parameters:\n",
        "          Z (np.ndarray): Input to the activation function (e.g., output from a linear layer)\n",
        "        Returns:\n",
        "          np.ndarray: Element-wise maximum between 0 and Z\n",
        "        '''\n",
        "\n",
        "        # Apply ReLU: If Z > 0, keep Z; otherwise, set to 0\n",
        "        return np.maximum(0, Z)\n",
        "\n",
        "    def backward(self, Z, A):\n",
        "        '''\n",
        "        Backward pass of the ReLU activation function.\n",
        "\n",
        "        Parameters:\n",
        "          Z (np.ndarray): Input to the ReLU during the forward pass.\n",
        "          A (np.ndarray): Output of the ReLU during the forward pass, containing gradients from the next layer.\n",
        "        '''\n",
        "\n",
        "        # Copy the gradient from the next layer\n",
        "        Z.grad = A.grad.copy()\n",
        "\n",
        "        # Set gradients to zero for elements where Z <= 0\n",
        "        Z.grad[Z <= 0] = 0\n"
      ],
      "metadata": {
        "id": "3fT-bdUfeGai"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLYz9w7t-2tG"
      },
      "source": [
        "### Sequential Class"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Sequential_layers():\n",
        "    def __init__(self, layers):\n",
        "        '''\n",
        "        Initializes the Sequential layers object with a list of layers\n",
        "\n",
        "        Parameters:\n",
        "          layers (list): A list of layer objects.\n",
        "        Atributes:\n",
        "          self.layers (list)\n",
        "          self.x (np.ndarray)\n",
        "          self.outputs (dict)\n",
        "        '''\n",
        "\n",
        "        # Store the list of layers\n",
        "        self.layers = layers\n",
        "        # Placeholder Input/output during forward pass\n",
        "        self.x = None\n",
        "        # Dictionary to save the outputs\n",
        "        self.outputs = {}\n",
        "\n",
        "\n",
        "    def __call__(self, X):\n",
        "        '''\n",
        "        Performs the forward pass through all layers sequentially\n",
        "\n",
        "        Parameters:\n",
        "          X (np.ndarray): The input to the network, (input_size, batch_size)\n",
        "        Returns:\n",
        "          np.ndarray: The final output of the network\n",
        "        '''\n",
        "\n",
        "        # Save the input to the first layer\n",
        "        self.x = X\n",
        "        # Store the initial input as '10'\n",
        "        self.outputs['l0'] = self.x\n",
        "\n",
        "        # Pass the input through each layer in sequence\n",
        "        for i, layer in enumerate(self.layers, 1):\n",
        "            self.x = layer(self.x)\n",
        "            self.outputs['l'+str(i)]=self.x\n",
        "        return self.x\n",
        "\n",
        "\n",
        "    def backward(self):\n",
        "      '''\n",
        "      Backward pass through all layers in reverse order\n",
        "      '''\n",
        "      # Iterate through layers in reverse order for backpropagation\n",
        "      for i in reversed(range(len(self.layers))):\n",
        "      # Pass the current and next layer outputs to the layer's backward method\n",
        "          self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])\n",
        "\n",
        "    def update(self, learning_rate = 1e-3):\n",
        "      '''\n",
        "      Updates the weights and biases of all layers\n",
        "      Parameters:\n",
        "        learning_rate (float): The learning rate used for weight updates.\n",
        "      '''\n",
        "      for layer in self.layers:\n",
        "        # Skip ReLu layers since they have no parameters to update\n",
        "          if isinstance(layer, ReLU): continue\n",
        "          # Update using their gradients\n",
        "          layer.W = layer.W - learning_rate * layer.W.grad\n",
        "          layer.b = layer.b - learning_rate * layer.b.grad\n",
        "\n",
        "    def predict(self, X):\n",
        "      '''\n",
        "      Forward pass and returns the predicted class for each sample\n",
        "      Parameters:\n",
        "        X (np.ndarray): The input to the network, (input_size, batch_size)\n",
        "      Returns:\n",
        "        np.ndarray: The predicted class for each sample\n",
        "      '''\n",
        "      # Return the class with the highest score\n",
        "      return np.argmax(self.__call__(X))"
      ],
      "metadata": {
        "id": "z7Pv_7_wc833"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJsZxT0e-2tG"
      },
      "source": [
        "### Cost Function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmaxXEntropy(x, y):\n",
        "    '''\n",
        "    Computes the softmax activation, cross-entropy loss, and the gradient of the loss\n",
        "\n",
        "    Parameters:\n",
        "      x (np.ndarray): The logits (raw scores) for each class, (num_classes, batch_size)\n",
        "      y (np.ndarray): The `y` labels, (batch_size,)\n",
        "\n",
        "    Returns:\n",
        "      preds (np.ndarray): The predicted probabilities for each class, (num_classes, batch_size)\n",
        "      cost (float): The average cross-entropy loss over the batch\n",
        "    '''\n",
        "\n",
        "    # Get the batch size (number of samples in the batch)\n",
        "    batch_size = x.shape[1]\n",
        "\n",
        "    # Compute the softmax probabilities\n",
        "\n",
        "    # Exponentiate the logits for each class\n",
        "    exp_scores = np.exp(x)\n",
        "    # Normalize to get probabilities per sample\n",
        "    probs = exp_scores / exp_scores.sum(axis=0)\n",
        "    # Save the probabilities for predictions\n",
        "    preds = probs.copy()\n",
        "\n",
        "    # Convert `y` labels to integers\n",
        "    y = y.astype(int)\n",
        "\n",
        "    # Handle cases where y might have out-of-bounds indices (e.g., due to data corruption)\n",
        "    valid_indices = np.clip(y.squeeze(), 0, probs.shape[0] - 1)  # Ensure indices are within [0, num_classes-1]\n",
        "\n",
        "    # Extract the predicted probabilities for the correct classes\n",
        "    y_hat = probs[valid_indices, np.arange(batch_size)]\n",
        "\n",
        "    # Compute the cross-entropy loss\n",
        "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
        "\n",
        "    # Backpropagation: Compute the gradient of the loss w.r.t. logits\n",
        "    probs[valid_indices, np.arange(batch_size)] -= 1\n",
        "    # Save the gradient of the loss w.r.t. the input `x`\n",
        "    x.grad = probs.copy()\n",
        "\n",
        "    return preds, cost"
      ],
      "metadata": {
        "id": "FRmLtOENc9eE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBVDxdPl-2tH"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, epochs, mb_size=128, learning_rate = 1e-3):\n",
        "  '''\n",
        "  Trains the model over a specific number of epochs.\n",
        "\n",
        "  Parameters:\n",
        "    model: The neural network model to be trained (e.g., Sequential_layers instance).\n",
        "    epochs (int): The number of times the entire training dataset is processed.\n",
        "    mb_size (int): The size of each mini-batch. Default is 128.\n",
        "    learning_rate (float): The step size for updating model parameters. Default is 1e-3.\n",
        "  '''\n",
        "  # Loop through the number of epochs\n",
        "  for epoch in range(epochs):\n",
        "    # Iterate through the training data in mini-batches\n",
        "    for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
        "      # Forward pass through the model\n",
        "      # Transpose `x` to match the expected shape\n",
        "      scores = model(x.T.view(np_tensor))\n",
        "\n",
        "      # Softmax and cross-entropy loss\n",
        "      _, cost = softmaxXEntropy(scores, y)\n",
        "\n",
        "      # Backward pass to compute gradients\n",
        "      model.backward()\n",
        "\n",
        "      # Update parameters using the computed gradients\n",
        "      model.update(learning_rate)\n",
        "\n",
        "    # Using this condition to avoid printing all the epochs\n",
        "    if epoch % 10 == 0:\n",
        "      print(f'Epoch: {epoch} | Cost: {cost:.4f} | Accuracy: {accuracy(x_val, y_val, mb_size):.3f}')"
      ],
      "metadata": {
        "id": "mgRoG5Jdc-8A"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUZPs8B_-2tH"
      },
      "source": [
        "### Create and train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5croE3-P-2tH"
      },
      "outputs": [],
      "source": [
        "def accuracy(x, y, mb_size):\n",
        "  '''\n",
        "  Accuracy of the model\n",
        "\n",
        "  Parameters:\n",
        "    x (np.ndarray): The input to the network, (input_size, batch_size)\n",
        "    y (np.ndarray): The `y` labels, (batch_size,)\n",
        "    mb_size (int): The size of each mini-batch.\n",
        "\n",
        "  Returns:\n",
        "    float: The accuracy of the model on the given data.\n",
        "  '''\n",
        "  # Counter of the correct predictions\n",
        "  correct = 0\n",
        "  # Counter of total number of samples\n",
        "  total = 0\n",
        "\n",
        "\n",
        "  # Iterate over the dataset in mini-batches\n",
        "  for i, (x, y) in enumerate(create_minibatches(mb_size, x, y)):\n",
        "      # Forward pass to get the predictions\n",
        "      # Transpose to match model expectations\n",
        "      pred = model(x.T.view(np_tensor))\n",
        "\n",
        "      # Compare the predicted class to the true class\n",
        "      correct += np.sum(np.argmax(pred, axis=0) == y.squeeze())\n",
        "\n",
        "      # Update the total number of samples processed\n",
        "      total += pred.shape[1]\n",
        "  return correct/total"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model initialization\n",
        "model = Sequential_layers([\n",
        "    Linear(784, 200), # 784 features, 200 neurons\n",
        "    ReLU(),           # Activation function\n",
        "    Linear(200, 200), # Hidden layer: 200 neurons to another 200 neurons\n",
        "    ReLU(),           # Activation function\n",
        "    Linear(200, 24)   # Output layer: 200 neurons, 24 classes\n",
        "])\n",
        "\n",
        "# Training\n",
        "mb_size = 512         # mini-batch size\n",
        "learning_rate = 1e-4  # learning rate for gradient descent\n",
        "epochs = 100          # number of training epochs"
      ],
      "metadata": {
        "id": "DWV6l_fmepBF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, epochs, mb_size, learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGn6KaiPetSA",
        "outputId": "09e3ffb9-a6e3-4f01-c711-01371c2d843b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Cost: 1.1389 | Accuracy: 0.553\n",
            "Epoch: 10 | Cost: 0.0390 | Accuracy: 0.745\n",
            "Epoch: 20 | Cost: 0.0138 | Accuracy: 0.759\n",
            "Epoch: 30 | Cost: 0.0084 | Accuracy: 0.762\n",
            "Epoch: 40 | Cost: 0.0064 | Accuracy: 0.760\n",
            "Epoch: 50 | Cost: 0.0042 | Accuracy: 0.760\n",
            "Epoch: 60 | Cost: 0.0035 | Accuracy: 0.759\n",
            "Epoch: 70 | Cost: 0.0026 | Accuracy: 0.757\n",
            "Epoch: 80 | Cost: 0.0022 | Accuracy: 0.758\n",
            "Epoch: 90 | Cost: 0.0019 | Accuracy: 0.759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQduHndi-2tH"
      },
      "source": [
        "### Test your model on Random data from your test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wGeFMsJ_-2tH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "8b59f360-e93c-48e5-b310-d5b772a83ddd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted sign: a | Actual sign: a\n"
          ]
        }
      ],
      "source": [
        "# Select a random index from the test set\n",
        "idx = np.random.randint(len(y_test))\n",
        "\n",
        "# Plot the image\n",
        "# Reshape the test sample from a 1D array (784,) to a 2D grid (28x28) for visualization.\n",
        "plot_number(x_test[idx].reshape(28,28))\n",
        "\n",
        "# Predict the class for the selected test image\n",
        "# Reshape the image to a column vector (784, 1) to match the model's input shape.\n",
        "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
        "\n",
        "# Print the result\n",
        "print(f'Predicted sign: {alphabet[pred]} | Actual sign: {alphabet[y_test[idx]]}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}